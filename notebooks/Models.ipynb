{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloading import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..................................................'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'.'*50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# +---------------------+----------------+\n",
    "# |       Property      | Importance (%) |\n",
    "# +---------------------+----------------+\n",
    "# |......................................|\n",
    "# |        CLDAP        |      <1 %      |\n",
    "# |      is_weekday     |      <1 %      |\n",
    "# |         DNS         |      <1 %      |\n",
    "# |      SYN Attack     |      <1 %      |\n",
    "# |     Generic UDP     |      <1 %      |\n",
    "# |         NTP         |      <1 %      |\n",
    "# |  IPv4 fragmentation |      <1 %      |\n",
    "# |         CoAP        |      <1 %      |\n",
    "# |         SNMP        |      <1 %      |\n",
    "# |         SSDP        |      <1 %      |\n",
    "# |     TCP Anomaly     |      <1 %      |\n",
    "# |       CHARGEN       |      <1 %      |\n",
    "# |  other_attack_codes |      <1 %      |\n",
    "# |         RDP         |      0 %       |\n",
    "# +---------------------+----------------+\n",
    "\n",
    "irrelevants = [\n",
    "    'CLDAP',\n",
    "    'is_weekday',\n",
    "    'DNS',\n",
    "    'SYN Attack',\n",
    "    'Generic UDP',\n",
    "    'NTP',\n",
    "    'IPv4 fragmentation',\n",
    "    'CoAP',\n",
    "    'SNMP',\n",
    "    'SSDP',\n",
    "    'TCP Anomaly',\n",
    "    'CHARGEN',\n",
    "    'other_attack_codes',\n",
    "    'RDP'\n",
    "]\n",
    "irrelevants = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATA_TRAIN         = '../data/preprocessed-v2/train_vectors_scaled.csv'\n",
    "PATH_DATA_VALIDATION    = '../data/preprocessed-v2/validation_vectors_scaled.csv'\n",
    "PATH_DATA_TEST          = '../data/preprocessed-v2/test_vectors_scaled.csv'\n",
    "PATH_DATA_GEN          = '../data/preprocessed-v2/generalisation_vectors_scaled.csv'\n",
    "TEST_SIZE = .2\n",
    "UNIQUE_COLUMNS = False\n",
    "\n",
    "(training_data_df, training_target_df) = get_all_data(\n",
    "    path_all_vectors=PATH_DATA_TRAIN, unique=UNIQUE_COLUMNS, remove_columns=['is_synthetic'] + irrelevants)\n",
    "\n",
    "(validation_data_df, validation_target_df) = get_all_data(\n",
    "    path_all_vectors=PATH_DATA_VALIDATION, unique=UNIQUE_COLUMNS, remove_columns=irrelevants)\n",
    "\n",
    "(test_data_df, test_target_df) = get_all_data(\n",
    "    path_all_vectors=PATH_DATA_TEST, unique=UNIQUE_COLUMNS, remove_columns=irrelevants)\n",
    "\n",
    "(gen_data_df, gen_target_df) = get_all_data(\n",
    "    path_all_vectors=PATH_DATA_GEN, unique=UNIQUE_COLUMNS, remove_columns=irrelevants)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assert inputs are of same length\n",
    "assert training_data_df.columns.to_list() == validation_data_df.columns.to_list() == test_data_df.columns.to_list() == gen_data_df.columns.to_list()\n",
    "assert training_target_df.columns.to_list() == validation_target_df.columns.to_list() == test_target_df.columns.to_list() == gen_target_df.columns.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Avg packet len', 'CHARGEN', 'CLDAP', 'CoAP', 'DNS', 'Data speed', 'Generic UDP', 'High volume traffic', 'IPv4 fragmentation', 'NTP', 'Packet speed', 'Port number', 'RDP', 'SNMP', 'SSDP', 'SYN Attack', 'Significant flag', 'Source IP count', 'Suspicious traffic', 'TCP Anomaly', 'is_weekday', 'other_attack_codes', 'time_of_day', 'victim IP num']\n",
      "['Avg packet len', 'CHARGEN', 'CLDAP', 'CoAP', 'DNS', 'Data speed', 'Generic UDP', 'High volume traffic', 'IPv4 fragmentation', 'NTP', 'Packet speed', 'Port number', 'RDP', 'SNMP', 'SSDP', 'SYN Attack', 'Significant flag', 'Source IP count', 'Suspicious traffic', 'TCP Anomaly', 'is_weekday', 'other_attack_codes', 'time_of_day', 'victim IP num']\n",
      "['Avg packet len', 'CHARGEN', 'CLDAP', 'CoAP', 'DNS', 'Data speed', 'Generic UDP', 'High volume traffic', 'IPv4 fragmentation', 'NTP', 'Packet speed', 'Port number', 'RDP', 'SNMP', 'SSDP', 'SYN Attack', 'Significant flag', 'Source IP count', 'Suspicious traffic', 'TCP Anomaly', 'is_weekday', 'other_attack_codes', 'time_of_day', 'victim IP num']\n",
      "['Avg packet len', 'CHARGEN', 'CLDAP', 'CoAP', 'DNS', 'Data speed', 'Generic UDP', 'High volume traffic', 'IPv4 fragmentation', 'NTP', 'Packet speed', 'Port number', 'RDP', 'SNMP', 'SSDP', 'SYN Attack', 'Significant flag', 'Source IP count', 'Suspicious traffic', 'TCP Anomaly', 'is_weekday', 'other_attack_codes', 'time_of_day', 'victim IP num']\n"
     ]
    }
   ],
   "source": [
    "print((training_data_df.columns.to_list()))\n",
    "print((validation_data_df.columns.to_list()))\n",
    "print((test_data_df.columns.to_list()))\n",
    "print((gen_data_df.columns.to_list()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = training_data_df.to_numpy()\n",
    "X_validation = validation_data_df.to_numpy()\n",
    "X_test = test_data_df.to_numpy()\n",
    "X_gen = gen_data_df.to_numpy()\n",
    "\n",
    "y_train = training_target_df.to_numpy().squeeze(1)\n",
    "y_validation = validation_target_df.to_numpy().squeeze(1)\n",
    "y_test = test_target_df.to_numpy().squeeze(1)\n",
    "y_gen = gen_target_df.to_numpy().squeeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape:  (1346829, 24)\n",
      "X_validation.shape:  (1247266, 24)\n",
      "X_test.shape:  (1233449, 24)\n",
      "X_gen.shape:  (2452610, 24)\n"
     ]
    }
   ],
   "source": [
    "print('X_train.shape: ', X_train.shape)\n",
    "print('X_validation.shape: ', X_validation.shape)\n",
    "print('X_test.shape: ', X_test.shape)\n",
    "print('X_gen.shape: ', X_gen.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train.shape:  (1346829,)\n",
      "y_validation.shape:  (1247266,)\n",
      "y_test.shape:  (1233449,)\n",
      "y_gen.shape:  (2452610,)\n"
     ]
    }
   ],
   "source": [
    "print('y_train.shape: ', y_train.shape)\n",
    "print('y_validation.shape: ', y_validation.shape)\n",
    "print('y_test.shape: ', y_test.shape)\n",
    "print('y_gen.shape: ', y_gen.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# MODEL INIT\n",
    "# model = RandomForestClassifier(\n",
    "#     verbose=True,\n",
    "#     max_depth=20,\n",
    "#     max_features=0.7,\n",
    "#     n_estimators=100,\n",
    "#     bootstrap=True,\n",
    "#     oob_score=False,\n",
    "#     )\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,\n",
    "    learning_rate=1.0,\n",
    "    max_depth=1,\n",
    "    random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAINING\n",
    "\n",
    "_ = model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import defaultdict\n",
    "\n",
    "# count = defaultdict(int)\n",
    "# for tree in model.estimators_:\n",
    "#     print(tree.get_depth(), end=', ')\n",
    "#     count[tree.get_depth()] += 1\n",
    "# count = dict(count)\n",
    "# for item, key in count.items():\n",
    "#     print(f'{key} trees have length {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 87.73578531498802 %\n",
      "Accuracy: 72.17241550719734 %\n",
      "Accuracy: 83.09844995617979 %\n",
      "Accuracy: 86.15801126147247 %\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def test(dataset:np.ndarray, target:np.ndarray):\n",
    "    # get predictions\n",
    "    y_pred = model.predict(dataset)\n",
    "\n",
    "    matches = np.count_nonzero(target == y_pred)\n",
    "    print(f'Accuracy: {100 * matches / len(target)} %')\n",
    "\n",
    "\n",
    "test(X_train, y_train)\n",
    "test(X_validation, y_validation)\n",
    "test(X_test, y_test)\n",
    "test(X_gen, y_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "info_data = list(training_data_df.columns.values)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = [\"Property\", \"Importance (%)\"]\n",
    "\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]\n",
    "\n",
    "for i in indices:\n",
    "    imp = 100 * importances[i]\n",
    "\n",
    "    if imp > 0:\n",
    "        if int(imp) == 0:\n",
    "            imp = '<1 %'\n",
    "        else:\n",
    "            imp = f'{int(imp)} %'\n",
    "    else:\n",
    "        imp = '0 %'\n",
    "\n",
    "\n",
    "    table.add_row([info_data[i], imp])\n",
    "\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WanDB init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert False, \"WanDB not yet needed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# start a new wandb run and add your model hyperparameters\n",
    "wandb.init(project='Halado_Adatelemzes_Labor', config=model.get_params())\n",
    "\n",
    "# Add additional configs to wandb\n",
    "wandb.config.update({\"test_size\" : TEST_SIZE,\n",
    "                    \"train_len\" : len(X_train),\n",
    "                    \"test_len\" : len(X_validation)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.sklearn import plot_precision_recall, plot_feature_importances\n",
    "from wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc\n",
    "\n",
    "y_probas = model.predict_proba(X_validation)\n",
    "\n",
    "# log additional visualisations to wandb\n",
    "plot_class_proportions(y_train, y_validation, info_data)\n",
    "# plot_learning_curve(model, X_train, y_train)\n",
    "plot_roc(y_validation, y_probas, info_data)\n",
    "plot_precision_recall(y_validation, y_probas, info_data)\n",
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
