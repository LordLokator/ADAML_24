{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from prettytable import PrettyTable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_attacks = '../data/all_vectors.csv'\n",
    "path_vectors = '../data/synthetic_vectors.csv'\n",
    "\n",
    "csv_data_attacks = pd.read_csv(path_attacks)\n",
    "csv_data_vectors = pd.read_csv(path_vectors)\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = csv_data_attacks.columns.tolist()\n",
    "table.add_row(csv_data_attacks.dtypes)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "for category, dtype in zip(csv_data_attacks, csv_data_attacks.dtypes):\n",
    "    if isinstance(dtype, np.dtypes.ObjectDType):\n",
    "        csv_data_attacks[category] = label_encoder.fit_transform(csv_data_attacks[category])\n",
    "\n",
    "table = PrettyTable()\n",
    "table.field_names = csv_data_attacks.columns.tolist()\n",
    "table.add_row(csv_data_attacks.dtypes)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# WanDB init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, datetime\n",
    "\n",
    "stamp_to_ms = lambda T : time.mktime(datetime.datetime.strptime(T, \"%Y-%m-%dT%H:%M:%S\").timetuple())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# load and process data\n",
    "data = csv_data_attacks.iloc[:, :-1]\n",
    "target = csv_data_attacks.iloc[:, -1]\n",
    "\n",
    "feature_names = csv_data_attacks.columns.to_numpy()\n",
    "labels = np.array(list(set(csv_data_attacks['Type'])))\n",
    "\n",
    "test_size = 0.2\n",
    "X_train, X_test, y_train, y_test = train_test_split(data, target, test_size=test_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# train model\n",
    "model = RandomForestClassifier(\n",
    "    verbose=True,\n",
    "    max_depth=3,\n",
    "    max_features=0.1,\n",
    "    n_estimators=1,\n",
    "    bootstrap=True,\n",
    "    oob_score=False,\n",
    "    )\n",
    "model.fit(X_train, y_train)\n",
    "model_params = model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "cnt = defaultdict(int)\n",
    "for tree in model.estimators_:\n",
    "    # print(tree.get_depth(), end=', ')\n",
    "    cnt[tree.get_depth()] += 1\n",
    "cnt = dict(cnt)\n",
    "for item, key in cnt.items():\n",
    "    print(f'{key} trees have length {item}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "\n",
    "# start a new wandb run and add your model hyperparameters\n",
    "wandb.init(project='Halado_Adatelemzes_Labor', config=model_params)\n",
    "\n",
    "# Add additional configs to wandb\n",
    "wandb.config.update({\"test_size\" : test_size,\n",
    "                    \"train_len\" : len(X_train),\n",
    "                    \"test_len\" : len(X_test)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "matches = np.count_nonzero(y_test == y_pred)\n",
    "print(f'Accuracy: {100 * matches / len(y_test)} %')\n",
    "\n",
    "y_probas = model.predict_proba(X_test)\n",
    "importances = model.feature_importances_\n",
    "indices = np.argsort(importances)[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wandb.sklearn import plot_precision_recall, plot_feature_importances\n",
    "from wandb.sklearn import plot_class_proportions, plot_learning_curve, plot_roc\n",
    "\n",
    "# log additional visualisations to wandb\n",
    "plot_class_proportions(y_train, y_test, labels)\n",
    "plot_learning_curve(model, X_train, y_train)\n",
    "plot_roc(y_test, y_probas, labels)\n",
    "plot_precision_recall(y_test, y_probas, labels)\n",
    "plot_feature_importances(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finish the wandb run\n",
    "wandb.finish()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
